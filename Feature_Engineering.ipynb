{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* num_private: 0 if x =0, 1, otherwise\n",
    "* amount_sth: 0 if x =0, 1, otherwise    \n",
    "* population: 0-0, 1-1, 2 otherwise    \n",
    "* construction_year: replace 0 with Nan, convert to age and normalize \n",
    "* longitude : 0 if < 5 and 1 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace 0 with nan\n",
    "import numpy as np\n",
    "print(train['construction_year'].head())\n",
    "\n",
    "train.construction_year.replace(0, np.nan, inplace=True);\n",
    "all_data.construction_year.replace(0, np.nan, inplace=True);\n",
    "\n",
    "print(train['construction_year'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert to age\n",
    "print(train['construction_year'].head())\n",
    "\n",
    "train['age'] =train['construction_year'].apply(lambda x: 2020-x);\n",
    "all_data['age'] =all_data['construction_year'].apply(lambda x: 2020-x);\n",
    "\n",
    "print(train['age'].head())\n",
    "\n",
    "train.drop('construction_year', axis=1, inplace=True);\n",
    "all_data.drop('construction_year', axis=1, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode amount_sth\n",
    "print(train['amount_tsh'].head())\n",
    "\n",
    "train['amount_coded'] =train['amount_tsh'].apply(lambda x: 0 if x==0.0 else 1);\n",
    "all_data['amount_coded'] =all_data['amount_tsh'].apply(lambda x: 0 if x==0.0 else 1);\n",
    "\n",
    "print(train['amount_coded'].head())\n",
    "\n",
    "train.drop('amount_tsh', axis=1, inplace=True);\n",
    "all_data.drop('amount_tsh', axis=1, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode num_private\n",
    "print(train['num_private'].head())\n",
    "\n",
    "train['num_coded'] =train['num_private'].apply(lambda x: 0 if x==0 else 1);\n",
    "all_data['num_coded'] =all_data['num_private'].apply(lambda x: 0 if x==0 else 1);\n",
    "\n",
    "print(train['num_coded'].head())\n",
    "\n",
    "train.drop('num_private', axis=1, inplace=True);\n",
    "all_data.drop('num_private', axis=1, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode logitude\n",
    "print(train['longitude'].head())\n",
    "\n",
    "train['longitude_coded'] =train['longitude'].apply(lambda x: 0 if x<5 else 1);\n",
    "all_data['longitude_coded'] =all_data['longitude'].apply(lambda x: 0 if x<5 else 1);\n",
    "\n",
    "print(train['longitude_coded'].head())\n",
    "\n",
    "train.drop('longitude', axis=1, inplace=True);\n",
    "all_data.drop('longitude', axis=1, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode population\n",
    "print(train['population'].head())\n",
    "\n",
    "train['population_coded'] =train['population'].apply(lambda x: 0 if x==0 else (1 if x==1 else 2));\n",
    "all_data['population_coded'] =all_data['population'].apply(lambda x: 0 if x==0 else (1 if x==1 else 2));\n",
    "\n",
    "print(train['population_coded'].head())\n",
    "\n",
    "train.drop('population', axis=1, inplace=True);\n",
    "all_data.drop('population', axis=1, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(train, index = 'label', values = ['age','longitude_coded','num_coded', 'amount_coded', 'population_coded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to categorical \n",
    "train.longitude_coded=train.longitude_coded.astype(\"object\");\n",
    "train.num_coded=train.num_coded.astype(\"object\");\n",
    "train.amount_coded=train.amount_coded.astype(\"object\");\n",
    "train.population_coded=train.population_coded.astype(\"object\");\n",
    "\n",
    "all_data.longitude_coded=all_data.longitude_coded.astype(\"object\");\n",
    "all_data.num_coded=all_data.num_coded.astype(\"object\");\n",
    "all_data.amount_coded=all_data.amount_coded.astype(\"object\");\n",
    "all_data.population_coded=all_data.population_coded.astype(\"object\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute nulls for continuous data \n",
    "train.age = train.age.fillna(train.age.mean());\n",
    "all_data.age = all_data.age.fillna(all_data.age.mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_cat_col = ['funder', 'installer', 'subvillage', 'public_meeting', 'permit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute nulls for categorical data \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "for col in na_cat_col:\n",
    "    imputer1 =SimpleImputer(strategy='most_frequent')\n",
    "    imputer1.fit(train[[col]])\n",
    "    train[col] = imputer1.transform(train[[col]]).ravel();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute nulls for categorical data \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "for col in na_cat_col:\n",
    "    imputer1 =SimpleImputer(strategy='most_frequent')\n",
    "    imputer1.fit(all_data[[col]])\n",
    "    all_data[col] = imputer1.transform(all_data[[col]]).ravel();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop scheme_name\n",
    "train.drop('scheme_name', axis = 1, inplace=True);\n",
    "all_data.drop('scheme_name', axis = 1, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric and categorical columns\n",
    "numerical_cols = [cname for cname in train.columns if train[cname].dtype in ['int64', 'float64']]\n",
    "categorical_cols = [cname for cname in train.columns if train[cname].dtype == \"object\" and train[cname].nunique() <20]\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created dummy variables from categories (also can use OneHotEncoder)\n",
    "all_dummies = pd.get_dummies(all_data[['gps_height', 'latitude', 'region_code', 'train_test', 'age',\n",
    "                                       'basin', 'public_meeting', 'permit', 'extraction_type_class', \n",
    "                                       'management_group', 'payment_type', 'quality_group', 'quantity_group', \n",
    "                                       'source_class', 'waterpoint_type_group', \n",
    "                                       'amount_coded', 'num_coded', 'longitude_coded', 'population_coded']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split to train test again\n",
    "X_train = all_dummies[all_dummies.train_test == 1].drop(['train_test'], axis =1)\n",
    "X_test = all_dummies[all_dummies.train_test == 0].drop(['train_test'], axis =1)\n",
    "\n",
    "\n",
    "y_train = all_data[all_data.train_test==1].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "all_dummies_scaled = all_dummies.copy()\n",
    "all_dummies_scaled[numerical_cols]= scale.fit_transform(all_dummies_scaled[numerical_cols])\n",
    "\n",
    "\n",
    "X_train_scaled = all_dummies_scaled[all_dummies.train_test == 1].drop(['train_test'], axis =1)\n",
    "X_test_scaled = all_dummies_scaled[all_dummies.train_test == 0].drop(['train_test'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dummies_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
